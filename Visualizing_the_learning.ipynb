{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ldUcPd8COw-u"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset,Dataset, DataLoader\n",
        "from torch.optim import SGD, Adam\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                   # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.1307], std=[0.3081])  # Normalize using FashionMNIST mean and std\n",
        "])\n",
        "\n",
        "trainset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x9rSzXzO7oo",
        "outputId": "ac5d9542-8758-4432-9f4a-6437ad858cef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 203kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.79MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 19.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "R, C = 7,7\n",
        "fig, ax = plt.subplots(R, C, figsize=(5,5))\n",
        "for label_class, plot_row in enumerate(ax):\n",
        "    for plot_cell in plot_row:\n",
        "        plot_cell.grid(False); plot_cell.axis('off')\n",
        "        ix = np.random.choice(1000)\n",
        "        im, label = trainset[ix]\n",
        "        plot_cell.imshow(im[0].cpu(), cmap='gray')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('data_snapshot.png', dpi=300)  # Save with high resolution\n",
        "plt.close()  # Close the figure to free up memory"
      ],
      "metadata": {
        "id": "UWFdZAHxSmqV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.simple_model = nn.Sequential(\n",
        "        nn.Conv2d(1,32,3,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "\n",
        "        nn.Conv2d(32,64,3,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "\n",
        "        nn.Conv2d(64,128,3,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(128*3*3,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10)\n",
        "    )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.simple_model(x)\n",
        "\n",
        "# 4. Initialize the model, loss function, and optimizer\n",
        "model = SimpleModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "POUTxOZtPGXd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, input_size=(1,28,28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKbW_UwfU-Ym",
        "outputId": "de8b993e-2cec-4222-f73f-943099bdc174"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "              ReLU-2           [-1, 32, 28, 28]               0\n",
            "         MaxPool2d-3           [-1, 32, 14, 14]               0\n",
            "            Conv2d-4           [-1, 64, 14, 14]          18,496\n",
            "              ReLU-5           [-1, 64, 14, 14]               0\n",
            "         MaxPool2d-6             [-1, 64, 7, 7]               0\n",
            "            Conv2d-7            [-1, 128, 7, 7]          73,856\n",
            "              ReLU-8            [-1, 128, 7, 7]               0\n",
            "         MaxPool2d-9            [-1, 128, 3, 3]               0\n",
            "          Flatten-10                 [-1, 1152]               0\n",
            "           Linear-11                  [-1, 512]         590,336\n",
            "             ReLU-12                  [-1, 512]               0\n",
            "           Linear-13                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 688,138\n",
            "Trainable params: 688,138\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.77\n",
            "Params size (MB): 2.63\n",
            "Estimated Total Size (MB): 3.40\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 6\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Track accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Print statistics after each epoch\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}, Accuracy: {100 * correct/total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1BTX8qyVYsu",
        "outputId": "56c3c48f-9e3b-44fc-e68c-1a0ab89b8bbf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/6], Loss: 0.4257, Accuracy: 84.31%\n",
            "Epoch [2/6], Loss: 0.2632, Accuracy: 90.25%\n",
            "Epoch [3/6], Loss: 0.2183, Accuracy: 91.79%\n",
            "Epoch [4/6], Loss: 0.1864, Accuracy: 93.14%\n",
            "Epoch [5/6], Loss: 0.1630, Accuracy: 93.87%\n",
            "Epoch [6/6], Loss: 0.1386, Accuracy: 94.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_layer(layers,loader):\n",
        "  image = visualize_image(loader)\n",
        "  image = image.to(device)\n",
        "  print(image.shape)\n",
        "  for i, layer in enumerate(layers):\n",
        "    outputs = layer(image[None])[0].to('cpu').detach()\n",
        "    label = f'ConvLayer_{i}'\n",
        "\n",
        "    # visualize image\n",
        "    cols = int(np.ceil(np.sqrt(outputs.shape[0])))\n",
        "    rows = int(np.ceil(outputs.shape[0] / cols))\n",
        "    print(R,C)\n",
        "    fig, ax = plt.subplots(rows, cols, figsize=(cols*2,rows*2))\n",
        "    for idx, axis in enumerate(ax.flat):\n",
        "      if idx >= outputs.shape[0]:\n",
        "        axis.remove()\n",
        "      else:\n",
        "        axis.grid(False); axis.axis('off')\n",
        "        axis.set_title(label + \" Filter \"+str(idx))\n",
        "        axis.imshow(outputs[idx].cpu(), cmap='gray')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'conv_layer_{i}.png', dpi=300)  # Save with high resolution\n",
        "    plt.close()  # Close the figure to free up memory\n",
        "\n",
        "  #plt.show()\n",
        "\n",
        "def visualize_dense_layer(layer, loader, label='Dense layer 1'):\n",
        "  image = visualize_image(loader)\n",
        "  outputs = layer(image[None])[0].detach()\n",
        "\n",
        "  print(outputs.shape)\n",
        "  plt.figure(figsize=(100,10))\n",
        "  plt.imshow(outputs.cpu())\n",
        "\n",
        "\n",
        "def visualize_image(loader):\n",
        "  # take the random image\n",
        "  size = len(loader.dataset)\n",
        "  rnd =  np.random.choice(size)\n",
        "  image, label = loader.dataset[rnd]\n",
        "  plt.imshow(image[0].cpu())\n",
        "  plt.axis('off')\n",
        "  plt.savefig(f'ConvInputImage.png', dpi=300)  # Save with high resolution\n",
        "  plt.close()\n",
        "  #plt.show()\n",
        "  return image"
      ],
      "metadata": {
        "id": "BDWnyo5GV6DN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Visualize first conv\n",
        "first_layer=nn.Sequential(*list(model.simple_model.children())[:1]) # first conv layer\n",
        "second_conv=nn.Sequential(*list(model.simple_model.children())[:4]) # mid conv layer\n",
        "third_conv=nn.Sequential(*list(model.simple_model.children())[:7]) # last conv layer\n",
        "layers = [first_layer, second_conv, third_conv]\n",
        "visualize_layer(layers,trainloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD0F9Z_xfazE",
        "outputId": "0a4707c4-bca9-492c-82d2-1664c9b4f359"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "7 7\n",
            "7 7\n",
            "7 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize flatten & dense layers"
      ],
      "metadata": {
        "id": "bjXuGELoEJXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=2498, shuffle=True, num_workers=2,drop_last=True)"
      ],
      "metadata": {
        "id": "iN2JId-FM74r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(trainloader))"
      ],
      "metadata": {
        "id": "6Fh9mNmcFW01"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = x[y==1] # taking any one class as an example\n",
        "len(x2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA_Wzad3Ft6K",
        "outputId": "8f39e98a-270d-4cf2-ef8f-2ef4916bdc61"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "272"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = x2.view(len(x2),1,28,28)"
      ],
      "metadata": {
        "id": "Be0UxGLGFxAb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_layer=nn.Sequential(*list(model.simple_model.children())[:10])\n",
        "flatten_layer_output = flatten_layer(x2.to(device)).detach()\n",
        "print(flatten_layer_output.shape)\n",
        "plt.figure(figsize=(100,10))\n",
        "plt.imshow(flatten_layer_output.cpu())#,cmap='gray')\n",
        "\n",
        "plt.savefig('Flatten_layer.png',dpi=300)\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT4Qk9mLMiCE",
        "outputId": "d43fcab6-d615-4b61-9590-013636f80ee5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([272, 1152])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_dense=nn.Sequential(*list(model.simple_model.children())[:11])\n",
        "flatten_layer_output = first_dense(x2.to(device)).detach()\n",
        "#flatten_layer_output.shape\n",
        "\n",
        "plt.figure(figsize=(100,10))\n",
        "plt.imshow(flatten_layer_output.cpu(),cmap='gray')\n",
        "\n",
        "plt.savefig('DenseLayer1.png',dpi=300)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "kmLLwZxcELFa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Visualize the last dense layer\n",
        "last_dense=nn.Sequential(*list(model.simple_model.children())[:13])\n",
        "flatten_layer_output = last_dense(x2.to(device)).detach()\n",
        "# flatten_layer_output.shape\n",
        "plt.figure(figsize=(100,10))\n",
        "plt.imshow(flatten_layer_output.cpu(),cmap='gray')\n",
        "plt.savefig('LastDenseLayer.png',dpi=300)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "rdZQYsfOEY8z"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}